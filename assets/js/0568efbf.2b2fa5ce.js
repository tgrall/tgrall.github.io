"use strict";(self.webpackChunktgrall_blog=self.webpackChunktgrall_blog||[]).push([[17184],{3905:(e,a,t)=>{t.d(a,{Zo:()=>c,kt:()=>d});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function l(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=n.createContext({}),s=function(e){var a=n.useContext(p),t=a;return e&&(t="function"==typeof e?e(a):l(l({},a),e)),t},c=function(e){var a=s(e.components);return n.createElement(p.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},m=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),m=s(t),d=r,k=m["".concat(p,".").concat(d)]||m[d]||u[d]||o;return t?n.createElement(k,l(l({ref:a},c),{},{components:t})):n.createElement(k,l({ref:a},c))}));function d(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=t.length,l=new Array(o);l[0]=m;var i={};for(var p in a)hasOwnProperty.call(a,p)&&(i[p]=a[p]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=t[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,t)}m.displayName="MDXCreateElement"},17555:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>s});var n=t(87462),r=(t(67294),t(3905));const o={title:"Setting up Spark Dynamic Allocation on MapR",categories:"spark yarn mapr"},l=void 0,i={permalink:"/blog/2016/09/01/setting-up-spark-dynamic-allocation-on-mapr",editUrl:"https://github.dev/tgrall/tgrall.github.io/blob/main/blog/2016-09-01-setting-up-spark-dynamic-allocation-on-mapr.md",source:"@site/blog/2016-09-01-setting-up-spark-dynamic-allocation-on-mapr.md",title:"Setting up Spark Dynamic Allocation on MapR",description:"Apache Spark can use various cluster manager to execute application (Stand Alone, YARN, Apache Mesos). When you install Apache Spark on MapR you can submit application in a Stand Alone mode or using YARN.",date:"2016-09-01T00:00:00.000Z",formattedDate:"September 1, 2016",tags:[],readingTime:2.155,hasTruncateMarker:!0,authors:[],frontMatter:{title:"Setting up Spark Dynamic Allocation on MapR",categories:"spark yarn mapr"},prevItem:{title:"Streaming Analytics in a Digitally Industrialized World",permalink:"/blog/2016/09/26/streaming-analytics-in-a-digitally-industrialized-world"},nextItem:{title:"Save MapR Streams messages into MapR DB JSON",permalink:"/blog/2016/03/30/save-mapr-streams-messages-into-mapr-db-json"}},p={authorsImageUrls:[]},s=[{value:"Prerequisites",id:"prerequisites",level:4},{value:"Enabling Dynamic Allocation in Apache Spark",id:"enabling-dynamic-allocation-in-apache-spark",level:3},{value:"Enabling Spark External Shuffle for YARN",id:"enabling-spark-external-shuffle-for-yarn",level:3},{value:"Add Spark Shuffle to YARN classpath",id:"add-spark-shuffle-to-yarn-classpath",level:4},{value:"Restart YARN",id:"restart-yarn",level:4},{value:"Submitting a Spark Job",id:"submitting-a-spark-job",level:3}],c={toc:s};function u(e){let{components:a,...t}=e;return(0,r.kt)("wrapper",(0,n.Z)({},c,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Apache Spark can use various cluster manager to execute application (Stand Alone, YARN, Apache Mesos). When you install Apache Spark on MapR you can submit application in a Stand Alone mode or using YARN."),(0,r.kt)("p",null,"This article focuses on YARN and Dynamic Allocation, a feature that lets Spark add or remove executors dynamically based on the workload. You can find more information about this feature in this presentation from Databricks:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://www.slideshare.net/databricks/dynamic-allocation-in-spark"},"Dynamic Allocation in Spark"))),(0,r.kt)("p",null,"Let\u2019s see how to configure Spark and YARN to use dynamic allocation (that is disabled by default)."),(0,r.kt)("h4",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"MapR Converged Data Platform Cluster"),(0,r.kt)("li",{parentName:"ul"},"Apache Spark for MapR installed")),(0,r.kt)("p",null,"This example has been described for MapR 5.2 with Apache Spark 1.6.1, you just need to adapt the version to your environment."),(0,r.kt)("h3",{id:"enabling-dynamic-allocation-in-apache-spark"},"Enabling Dynamic Allocation in Apache Spark"),(0,r.kt)("p",null,"The first thing to do is to enable Dynamic Allocation in Spark, for this you need to edit the spark configuration file on each Spark node."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/spark/spark-1.6.1/conf/spark-defaults.conf\n")),(0,r.kt)("p",null,"and add the following entries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"spark.dynamicAllocation.enabled = true\nspark.shuffle.service.enabled = true\nspark.dynamicAllocation.minExecutors = 5 \nspark.executor.instances = 0\n")),(0,r.kt)("p",null,"You can find additional configuration options in the ",(0,r.kt)("a",{parentName:"p",href:"http://spark.apache.org/docs/1.6.1/configuration.html#dynamic-allocation"},"Apache Spark Documentation"),"."),(0,r.kt)("h3",{id:"enabling-spark-external-shuffle-for-yarn"},"Enabling Spark External Shuffle for YARN"),(0,r.kt)("p",null,"You have now to edit YARN configuration to add information about Spark Shuffle Service, edit the following file, on each YARN node:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/hadoop/hadoop-2.7.0/etc/hadoop/yarn-site.xml\n")),(0,r.kt)("p",null,"add these properties: "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce_shuffle,mapr_direct_shuffle,spark_shuffle</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>\n    <value>org.apache.spark.network.yarn.YarnShuffleService</value>\n  </property>\n")),(0,r.kt)("h4",{id:"add-spark-shuffle-to-yarn-classpath"},"Add Spark Shuffle to YARN classpath"),(0,r.kt)("p",null,"Spark Shuffle service must be added to the YARN classpath. The jar is located in the spark distribution:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/spark/spark-1.6.1/lib/spark-1.6.1-mapr-1605-yarn-shuffle.jar\n")),(0,r.kt)("p",null,"To achieve this add the jar in the following folder on each node:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/hadoop/hadoop-2.7.0/share/hadoop/yarn/lib\n")),(0,r.kt)("p",null,"You can either copyy the file or create a symlink:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ ln -s /opt/mapr/spark/spark-1.6.1/lib/spark-1.6.1-mapr-1605-yarn-shuffle.jar /opt/mapr/hadoop/hadoop-2.7.0/share/hadoop/yarn/lib\n")),(0,r.kt)("h4",{id:"restart-yarn"},"Restart YARN"),(0,r.kt)("p",null,"Since you have changed the YARN configuration ",(0,r.kt)("em",{parentName:"p"},"you must restart your node managers")," using the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ maprcli node services -name nodemanager -action restart -nodes [list of nodes]\n")),(0,r.kt)("h3",{id:"submitting-a-spark-job"},"Submitting a Spark Job"),(0,r.kt)("p",null,"Your MapR Cluster is not ready to use Spark dynamic allocation, this means that when you submit a job you do not need to specify any resource configuration, for example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/spark/spark-1.6.1/bin/spark-submit \\\n  --class com.mapr.demo.WordCountSorted \\\n  --master yarn \\\n  ~/spark-examples-1.0-SNAPSHOT.jar \\\n  /mapr/my.cluster.com/input/4gb_txt_file.txt \\\n  /mapr/my.cluster.com/user/mapr/output/\n")),(0,r.kt)("p",null,"note that you can still specify the resources, but in this case the dynamic allocation will not be used for this specific job, for example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"/opt/mapr/spark/spark-1.6.1/bin/spark-submit \\\n  --class com.mapr.demo.WordCountSorted \\\n  --master yarn \\\n  --num-executors 3\n  --executor-memory 1G \\\n  ~/spark-examples-1.0-SNAPSHOT.jar \\\n  /mapr/my.cluster.com/input/4gb_txt_file.txt \\\n  /mapr/my.cluster.com/user/mapr/output/\n")))}u.isMDXComponent=!0}}]);