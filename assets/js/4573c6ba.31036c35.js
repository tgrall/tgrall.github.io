(self.webpackChunktgrall_blog=self.webpackChunktgrall_blog||[]).push([[14180],{3905:function(t,e,n){"use strict";n.d(e,{Zo:function(){return u},kt:function(){return d}});var r=n(67294);function a(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function i(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(t);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,r)}return n}function o(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?i(Object(n),!0).forEach((function(e){a(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function l(t,e){if(null==t)return{};var n,r,a=function(t,e){if(null==t)return{};var n,r,a={},i=Object.keys(t);for(r=0;r<i.length;r++)n=i[r],e.indexOf(n)>=0||(a[n]=t[n]);return a}(t,e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(t);for(r=0;r<i.length;r++)n=i[r],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(a[n]=t[n])}return a}var c=r.createContext({}),p=function(t){var e=r.useContext(c),n=e;return t&&(n="function"==typeof t?t(e):o(o({},e),t)),n},u=function(t){var e=p(t.components);return r.createElement(c.Provider,{value:e},t.children)},s={inlineCode:"code",wrapper:function(t){var e=t.children;return r.createElement(r.Fragment,{},e)}},f=r.forwardRef((function(t,e){var n=t.components,a=t.mdxType,i=t.originalType,c=t.parentName,u=l(t,["components","mdxType","originalType","parentName"]),f=p(n),d=a,g=f["".concat(c,".").concat(d)]||f[d]||s[d]||i;return n?r.createElement(g,o(o({ref:e},u),{},{components:n})):r.createElement(g,o({ref:e},u))}));function d(t,e){var n=arguments,a=e&&e.mdxType;if("string"==typeof t||a){var i=n.length,o=new Array(i);o[0]=f;var l={};for(var c in e)hasOwnProperty.call(e,c)&&(l[c]=e[c]);l.originalType=t,l.mdxType="string"==typeof t?t:a,o[1]=l;for(var p=2;p<i;p++)o[p]=n[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}f.displayName="MDXCreateElement"},33357:function(t,e,n){"use strict";n.r(e),n.d(e,{frontMatter:function(){return l},contentTitle:function(){return c},metadata:function(){return p},assets:function(){return u},toc:function(){return s},default:function(){return d}});var r=n(22122),a=n(19756),i=(n(67294),n(3905)),o=["components"],l={title:"Getting started with Apache Flink and Kafka",categories:"kafka flink streaming how-to"},c=void 0,p={permalink:"/blog/2016/10/12/getting-started-with-apache-flink-and-kafka",editUrl:"https://github.dev/tgrall/tgrall.github.io/blob/main/blog/2016-10-12-getting-started-with-apache-flink-and-kafka.md",source:"@site/blog/2016-10-12-getting-started-with-apache-flink-and-kafka.md",title:"Getting started with Apache Flink and Kafka",description:"Introduction",date:"2016-10-12T00:00:00.000Z",formattedDate:"October 12, 2016",tags:[],readingTime:4.805,truncated:!0,authors:[],prevItem:{title:"Getting started with Apache Flink and Mapr Streams",permalink:"/blog/2016/10/17/getting-started-with-apache-flink-and-mapr-streams"},nextItem:{title:"Streaming Analytics in a Digitally Industrialized World",permalink:"/blog/2016/09/26/streaming-analytics-in-a-digitally-industrialized-world"}},u={authorsImageUrls:[]},s=[{value:"Introduction",id:"introduction",children:[]}],f={toc:s};function d(t){var e=t.components,n=(0,a.Z)(t,o);return(0,i.kt)("wrapper",(0,r.Z)({},f,n,{components:e,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://flink.apache.org/"},"Apache Flink")," is an open source platform for distributed stream and batch data processing. Flink is a streaming data flow engine with several APIs to create data streams oriented application."),(0,i.kt)("p",null,"It is very common for Flink applications to use ",(0,i.kt)("a",{parentName:"p",href:"http://kafka.apache.org/"},"Apache Kafka")," for data input and output. This article will guide you into  the steps to use Apache Flink with Kafka."),(0,i.kt)("p",null,"![]( center /images/posts/flink-kafka/flink-kafka.png Flink-Kafka )"))}d.isMDXComponent=!0}}]);