"use strict";(self.webpackChunktgrall_blog=self.webpackChunktgrall_blog||[]).push([[14180],{3905:(t,e,n)=>{n.d(e,{Zo:()=>s,kt:()=>d});var r=n(67294);function a(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function i(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(t);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,r)}return n}function o(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?i(Object(n),!0).forEach((function(e){a(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function l(t,e){if(null==t)return{};var n,r,a=function(t,e){if(null==t)return{};var n,r,a={},i=Object.keys(t);for(r=0;r<i.length;r++)n=i[r],e.indexOf(n)>=0||(a[n]=t[n]);return a}(t,e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(t);for(r=0;r<i.length;r++)n=i[r],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(a[n]=t[n])}return a}var c=r.createContext({}),p=function(t){var e=r.useContext(c),n=e;return t&&(n="function"==typeof t?t(e):o(o({},e),t)),n},s=function(t){var e=p(t.components);return r.createElement(c.Provider,{value:e},t.children)},f={inlineCode:"code",wrapper:function(t){var e=t.children;return r.createElement(r.Fragment,{},e)}},u=r.forwardRef((function(t,e){var n=t.components,a=t.mdxType,i=t.originalType,c=t.parentName,s=l(t,["components","mdxType","originalType","parentName"]),u=p(n),d=a,g=u["".concat(c,".").concat(d)]||u[d]||f[d]||i;return n?r.createElement(g,o(o({ref:e},s),{},{components:n})):r.createElement(g,o({ref:e},s))}));function d(t,e){var n=arguments,a=e&&e.mdxType;if("string"==typeof t||a){var i=n.length,o=new Array(i);o[0]=u;var l={};for(var c in e)hasOwnProperty.call(e,c)&&(l[c]=e[c]);l.originalType=t,l.mdxType="string"==typeof t?t:a,o[1]=l;for(var p=2;p<i;p++)o[p]=n[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},33357:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>f,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const i={title:"Getting started with Apache Flink and Kafka",categories:"kafka flink streaming how-to"},o=void 0,l={permalink:"/blog/2016/10/12/getting-started-with-apache-flink-and-kafka",editUrl:"https://github.dev/tgrall/tgrall.github.io/blob/main/blog/2016-10-12-getting-started-with-apache-flink-and-kafka.md",source:"@site/blog/2016-10-12-getting-started-with-apache-flink-and-kafka.md",title:"Getting started with Apache Flink and Kafka",description:"Introduction",date:"2016-10-12T00:00:00.000Z",formattedDate:"October 12, 2016",tags:[],readingTime:4.805,hasTruncateMarker:!0,authors:[],frontMatter:{title:"Getting started with Apache Flink and Kafka",categories:"kafka flink streaming how-to"},prevItem:{title:"Getting started with Apache Flink and Mapr Streams",permalink:"/blog/2016/10/17/getting-started-with-apache-flink-and-mapr-streams"},nextItem:{title:"Streaming Analytics in a Digitally Industrialized World",permalink:"/blog/2016/09/26/streaming-analytics-in-a-digitally-industrialized-world"}},c={authorsImageUrls:[]},p=[{value:"Introduction",id:"introduction",level:2}],s={toc:p};function f(t){let{components:e,...n}=t;return(0,a.kt)("wrapper",(0,r.Z)({},s,n,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://flink.apache.org/"},"Apache Flink")," is an open source platform for distributed stream and batch data processing. Flink is a streaming data flow engine with several APIs to create data streams oriented application."),(0,a.kt)("p",null,"It is very common for Flink applications to use ",(0,a.kt)("a",{parentName:"p",href:"http://kafka.apache.org/"},"Apache Kafka")," for data input and output. This article will guide you into  the steps to use Apache Flink with Kafka."),(0,a.kt)("p",null,"![]( center /images/posts/flink-kafka/flink-kafka.png Flink-Kafka )"))}f.isMDXComponent=!0}}]);